{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.join('../..'))\n",
    "# sys.path.append(os.path.join(os.environ['HAWQ_JET_TAGGING'], 'utilities'))\n",
    "\n",
    "from pulp import *\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 04:55:18.820315: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-13 04:55:18.897846: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 04:55:19.731844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jcampos/miniforge3/lib/python3.9/site-packages/ot/backend.py:2998: UserWarning: To use TensorflowBackend, you need to activate the tensorflow numpy API. You can activate it by running: \n",
      "from tensorflow.python.ops.numpy_ops import np_config\n",
      "np_config.enable_numpy_behavior()\n",
      "  register_backend(TensorflowBackend())\n"
     ]
    }
   ],
   "source": [
    "from utilities.compute_bops import compute_bops\n",
    "from model import AutoEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_file = \"/data/jcampos/hawq-jet-tagging/checkpoints/econ/10.31.2023-18.50.41/last.ckpt\"\n",
    "\n",
    "model = AutoEncoder(\n",
    "    accelerator=\"auto\", \n",
    "    quantize=False,\n",
    "    precision=[32, 32, 32],\n",
    "    learning_rate=1e-3,  \n",
    "    econ_type=\"baseline\",\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_file)[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcampos/miniforge3/lib/python3.9/site-packages/torchinfo/torchinfo.py:462: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "AutoEncoder                              [1, 1, 8, 8]              --\n",
       "├─BaseEncoder: 1-1                       [1, 16]                   --\n",
       "│    └─Conv2d: 2-1                       [1, 8, 4, 4]              80\n",
       "│    └─ReLU: 2-2                         [1, 8, 4, 4]              --\n",
       "│    └─Flatten: 2-3                      [1, 128]                  --\n",
       "│    └─Linear: 2-4                       [1, 16]                   2,064\n",
       "│    └─ReLU: 2-5                         [1, 16]                   --\n",
       "├─Sequential: 1-2                        [1, 1, 8, 8]              --\n",
       "│    └─Linear: 2-6                       [1, 128]                  2,176\n",
       "│    └─ReLU: 2-7                         [1, 128]                  --\n",
       "│    └─Unflatten: 2-8                    [1, 8, 4, 4]              --\n",
       "│    └─ConvTranspose2d: 2-9              [1, 8, 8, 8]              584\n",
       "│    └─ReLU: 2-10                        [1, 8, 8, 8]              --\n",
       "│    └─ConvTranspose2d: 2-11             [1, 1, 8, 8]              73\n",
       "│    └─Sigmoid: 2-12                     [1, 1, 8, 8]              --\n",
       "==========================================================================================\n",
       "Total params: 4,977\n",
       "Trainable params: 4,977\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.05\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 0.03\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(model, input_size=(1, 1, 8, 8))  # (B, C, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Quantization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [ 23.66148376 986.60961914]\n",
      "3 [ 23.52730751 718.11633301]\n",
      "4 [ 22.68955231 632.29559326]\n",
      "5 [ 22.25978661 597.82232666]\n",
      "6 [ 22.08265686 582.24053955]\n",
      "7 [ 22.0026474  574.79370117]\n",
      "8 [ 21.96077538 571.20532227]\n"
     ]
    }
   ],
   "source": [
    "MIN_BITWIDTH = 2\n",
    "MAX_BITWIDTH = 8\n",
    "LAYERS = ['conv', 'enc_dense']\n",
    "\n",
    "all_bit_widths = list(range(MIN_BITWIDTH,MAX_BITWIDTH+1))\n",
    "delta_weights = {}  # store the L2 norm. \n",
    "\n",
    "for bit_width in all_bit_widths:\n",
    "    tmp_delta_weights = []\n",
    "    \n",
    "    for idx, layer_name in enumerate(LAYERS):\n",
    "        # get layer to compute quant. error \n",
    "        layer = getattr(model.encoder, layer_name)\n",
    "        \n",
    "        # min and max for chosen bitwidth \n",
    "        q_min = -(2**bit_width)\n",
    "        q_max = (2**bit_width)-1\n",
    "\n",
    "        # quantize and dequantize weights\n",
    "        x = torch.clamp(layer.weight, q_min, q_max)\n",
    "        delta = (q_max-q_min)/(q_max-1)\n",
    "        x_integer = torch.round((x-q_min)/delta)\n",
    "        x = x_integer*delta+q_min\n",
    "\n",
    "        # compute the L2 norm. \n",
    "        l2_weight_perturbation = ((x.reshape(1,-1) - layer.weight.reshape(1,-1))**2).sum()\n",
    "        l2_weight_perturbation = l2_weight_perturbation.detach().numpy().item()\n",
    "        \n",
    "        # store resut\n",
    "        tmp_delta_weights.append(l2_weight_perturbation)\n",
    "\n",
    "    delta_weights[bit_width] = np.array(tmp_delta_weights)\n",
    "\n",
    "\n",
    "for bit_width in all_bit_widths:\n",
    "    print(f\"{bit_width} {delta_weights[bit_width]}\")\n",
    "    # print(f\"{bit_width} {delta_weights[bit_width]/np.array([ 1088, 2080, 1056, 165]).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23.66148376 986.60961914]\n",
      " [ 23.52730751 718.11633301]\n",
      " [ 22.68955231 632.29559326]\n",
      " [ 22.25978661 597.82232666]\n",
      " [ 22.08265686 582.24053955]\n",
      " [ 22.0026474  574.79370117]\n",
      " [ 21.96077538 571.20532227]]\n"
     ]
    }
   ],
   "source": [
    "# convert to numpy array \n",
    "l2_quant_pert = []\n",
    "\n",
    "for bit_width in delta_weights.keys():\n",
    "    l2_quant_pert.append(delta_weights[bit_width])\n",
    "\n",
    "l2_quant_pert = np.array(l2_quant_pert)\n",
    "print(l2_quant_pert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 BOPs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 - Integer Linear Programming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "args = args\n",
    "args.model_size_limit = 0.5 \n",
    "args.bops_limit = 0.0003 \n",
    "args.latency_limit = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of layers (for ILP setup)\n",
    "NUM_LAYERS = len(LAYERS)\n",
    "\n",
    "# number of paramers of each layer\n",
    "parameters = np.array([ 80, 2064])\n",
    "\n",
    "# Hutchinson_trace means the trace of Hessian for each weight matrix.\n",
    "Hutchinson_trace = np.array([5.3138685, 0.8988645])  # original (not normalized)\n",
    "\n",
    "# BOPs of each layer\n",
    "bops_2bit = np.array([55296, 47104, 47104, 3520])\n",
    "bops_3bit = np.array([72704, 67584, 32768, 5120])\n",
    "bops_4bit = np.array([90112, 92160, 45056, 7040]) \n",
    "bops_5bit = np.array([107520, 120832, 59392, 9280])\n",
    "bops_6bit = np.array([124928, 153600, 75776, 11840])\n",
    "bops_7bit = np.array([142336, 190464, 94208, 14720])\n",
    "bops_8bit = np.array([159744, 231424, 114688, 17920])\n",
    "bops_9bit = np.array([340992, 215040, 106496, 16640])\n",
    "bops_10bit = np.array([374784, 258048, 128000, 20000])\n",
    "bops_32bit = np.array([1118208, 2240512, 831119232, 174880])\n",
    "\n",
    "# bops = np.array([bops_2bit, bops_3bit, bops_4bit, bops_5bit, bops_6bit, bops_7bit, bops_8bit, bops_9bit, bops_10bit]).reshape(-1) / 1024\n",
    "bops = np.array([bops_4bit, bops_5bit, bops_6bit, bops_7bit, bops_8bit]).reshape(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model size \n",
    "model_size_32bit = np.sum(parameters) \n",
    "# model_size_limit = model_size_32bit * args.model_size_limit\n",
    "\n",
    "# bops\n",
    "# BOPS_LIMIT = np.sum(bops_32bit) * args.bops_limit \n",
    "BOPS_LIMIT = int(350e3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - ILP BOPs Size Constrait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the problem \n",
    "number_variables = Hutchinson_trace.shape[0]*len(l2_quant_pert) # NUM_LAYERS * BIT_WIDTH_OPTIONS\n",
    "\n",
    "# first get the variables\n",
    "variable = {}\n",
    "for i in range(number_variables):\n",
    "    variable[f\"x{i}\"] = LpVariable(f\"x{i}\", 0, 1, cat=LpInteger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = LpProblem(\"Model_Size\", LpMinimize)\n",
    "\n",
    "# add objective function, minimize model size \n",
    "# prob += sum([variable[f\"x{i}\"] * parameters[i%4] for i in range(num_variable) ]) <= model_size_limit \n",
    "\n",
    "# add objective function, minimize bops \n",
    "prob += sum([variable[f\"x{i}\"] * bops[i] for i in range(number_variables) ]) <= BOPS_LIMIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each layer has BIT_WIDTH_OPTIONS variables (5 in this case), each variable can either be 0 or 1 \n",
    "# an extra constraint is needed to chose one bitwidth per layer\n",
    "prob += sum([variable[f\"x{i}\"] for i in list(range(0, number_variables, NUM_LAYERS))]) == 1  \n",
    "prob += sum([variable[f\"x{i}\"] for i in list(range(1, number_variables, NUM_LAYERS))]) == 1\n",
    "prob += sum([variable[f\"x{i}\"] for i in list(range(2, number_variables, NUM_LAYERS))]) == 1\n",
    "prob += sum([variable[f\"x{i}\"] for i in list(range(3, number_variables, NUM_LAYERS))]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob += sum( [ variable[f\"x{i}\"] * l2_quant_pert.reshape(-1)[i] * Hutchinson_trace[i%NUM_LAYERS] for i in range(number_variables) ] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPSOL--GLPK LP/MIP Solver 5.0\n",
      "Parameter(s) specified in the command line:\n",
      " --cpxlp /tmp/b5caeafe96a04a58a6190ae648347b7e-pulp.lp -o /tmp/b5caeafe96a04a58a6190ae648347b7e-pulp.sol\n",
      " --tmlim 10000 --simplex\n",
      "Reading problem data from '/tmp/b5caeafe96a04a58a6190ae648347b7e-pulp.lp'...\n",
      "5 rows, 20 columns, 40 non-zeros\n",
      "20 integer variables, all of which are binary\n",
      "39 lines were read\n",
      "GLPK Integer Optimizer 5.0\n",
      "5 rows, 20 columns, 40 non-zeros\n",
      "20 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "5 rows, 20 columns, 40 non-zeros\n",
      "20 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  2.314e+05  ratio =  2.314e+05\n",
      "GM: min|aij| =  7.612e-01  max|aij| =  1.314e+00  ratio =  1.726e+00\n",
      "EQ: min|aij| =  5.805e-01  max|aij| =  1.000e+00  ratio =  1.723e+00\n",
      "2N: min|aij| =  3.438e-01  max|aij| =  1.000e+00  ratio =  2.909e+00\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 5\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "5 rows, 20 columns, 40 non-zeros\n",
      "*     0: obj =   2.615715763e+03 inf =   0.000e+00 (10)\n",
      "*     5: obj =   2.609086261e+03 inf =   0.000e+00 (0)\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+     5: mip =     not found yet >=              -inf        (1; 0)\n",
      "Solution found by heuristic: 2610.30897766\n",
      "Solution found by heuristic: 2610.26622307\n",
      "+     9: mip =   2.610266223e+03 >=     tree is empty   0.0% (0; 3)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n",
      "Time used:   0.0 secs\n",
      "Memory used: 0.1 Mb (60062 bytes)\n",
      "Writing MIP solution to '/tmp/b5caeafe96a04a58a6190ae648347b7e-pulp.sol'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Optimal'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solve the problem\n",
    "status = prob.solve(GLPK_CMD(msg=1, options=[\"--tmlim\", \"10000\",\"--simplex\"]))\n",
    "# get the result\n",
    "LpStatus[status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape ILP result \n",
    "result = []\n",
    "for i in range(number_variables):\n",
    "    result.append(value(variable[f\"x{i}\"]))\n",
    "\n",
    "result\n",
    "\n",
    "result = np.array(result).reshape(len(l2_quant_pert),-1)\n",
    "bitwidth_idxs = np.argmax(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit Width\tDense1\t\tDense2\t\tDense3\t\tDense4\n",
      " 4              0               0               0               0\n",
      " 5              0               1               1               1\n",
      " 6              0               0               0               0\n",
      " 7              0               0               0               0\n",
      " 8              1               0               0               0\n",
      "Total BOPs: 349248\n",
      "BOPs limit: 350000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bit Width\\tDense1\\t\\tDense2\\t\\tDense3\\t\\tDense4\")\n",
    "for idx in range(len(l2_quant_pert)):\n",
    "    print(f\"{all_bit_widths[idx]:2} \\\n",
    "          {result[idx][0]:4d} \\\n",
    "            {result[idx][1]:3d} \\\n",
    "            {result[idx][2]:3d} \\\n",
    "            {result[idx][3]:3d}\")\n",
    "\n",
    "# get total bops\n",
    "total_bops = 0\n",
    "for idx in range(NUM_LAYERS):\n",
    "    bops_index = bitwidth_idxs[idx]*NUM_LAYERS + idx\n",
    "    total_bops += bops[bops_index]\n",
    "\n",
    "print(f\"Total BOPs: {total_bops}\")\n",
    "print(f\"BOPs limit: {BOPS_LIMIT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25f1d7c570f47b2d86ad1fd9b4f66fba2fcbddd70cd883a3ef3509722d52581a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
